{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis for distributions of Alleles cross-Populations\n",
    "## Author: Efthymios Tzinis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the data \n",
    "agg_alleles_datapath = '../data/aggregated_alleles_new.xlsx'\n",
    "result_filepath = '../results/aggregated_allels_comparisons'\n",
    "\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "xls = pd.ExcelFile(agg_alleles_datapath)\n",
    "df = xls.parse(xls.sheet_names[0])\n",
    "valid_sheets = xls.sheet_names[:-1]\n",
    "print valid_sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gather information about a specific polymorphism for all populations \n",
    "alleles_agg_data = {}\n",
    "for poly in valid_sheets:\n",
    "    df = xls.parse(poly)\n",
    "    \n",
    "    # find indexes for alleles for all populations => pls allign all sheets!!\n",
    "    alleles_indexes = [6,7]\n",
    "    alleles_labels = map(lambda x: df['GENOTYPES'].loc[x],alleles_indexes)\n",
    "\n",
    "#     print \"Labels of alleles \" + str(alleles_labels)\n",
    "#     print \"Indexes in sheet \"+str(alleles_indexes)\n",
    "    \n",
    "    alleles_agg_data[poly] = {}\n",
    "    alleles_agg_data[poly]['data'] = df.loc[alleles_indexes]\n",
    "    alleles_agg_data[poly]['labels'] = alleles_labels\n",
    "print alleles_agg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import scipy.stats as stats\n",
    "\n",
    "def compute_odds_ratio_CI_95(data,odds_ratio):\n",
    "    val_in_list = list(data.flatten())\n",
    "    val_in_list = map(lambda x: 1/float(x),val_in_list)\n",
    "    sum_of_vals = sum(val_in_list)\n",
    "    \n",
    "    error = 1.96 * math.sqrt(sum_of_vals)\n",
    "    ln_or = math.log(odds_ratio)\n",
    "    \n",
    "    uci = math.exp(ln_or + error)\n",
    "    lci = math.exp(ln_or - error)\n",
    "    \n",
    "    return lci, uci\n",
    "    \n",
    "def compute_odds_ratio(data):\n",
    "    if data[0][1] == 0 or data[1][0] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return float(data[0][0] * data[1][1]) / (data[0][1] * data[1][0])\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0*np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * sp.stats.t._ppf((1+confidence)/2., n-1)\n",
    "    return m, m-h, m+h\n",
    "\n",
    "# from scipy.stats import chisquare\n",
    "# obs = np.array([[44, 468], [23, 477]])\n",
    "# obs = np.array([[180, 90], [60, 170]])\n",
    "# obs = np.array([[668, 338], [1585, 679]]).T\n",
    "# # obs = np.array([[1089, 3919], [679, 1585]])\n",
    "# # obs = np.array([[977, 29], [2069, 483]])\n",
    "# # obs = np.array([[4214, 794], [2069, 483]])\n",
    "# # chisq, pval_chi = chisquare(obs,ddof=0)\n",
    "# # print chisq, pval_chi\n",
    "# # chisq, pval_chi= sum(chisq) , sum(pval_chi)\n",
    "# # print chisq, pval_chi\n",
    "\n",
    "\n",
    "# oddsratio, pval_f = stats.fisher_exact(obs)\n",
    "# # print oddsratio, pval_f\n",
    "# # print compute_odds_ratio(obs)\n",
    "# lci, uci = compute_odds_ratio_CI_95(obs,oddsratio)\n",
    "# print \"{},{},{}-{}\".format(pval_f,oddsratio,lci, uci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xlwt\n",
    "\n",
    "def get_stats_from_matrix(data):\n",
    "    oddsratio, pval_f = stats.fisher_exact(data)\n",
    "    # print oddsratio, pval_f\n",
    "    # print compute_odds_ratio(obs)\n",
    "    lci, uci = compute_odds_ratio_CI_95(data,oddsratio)\n",
    "    if pval_f < 0.0001:\n",
    "        new_p_str = '< 0.0001'\n",
    "    else:\n",
    "        new_p_str = round(pval_f,4)\n",
    "    return \"{},{},{}-{}\".format(new_p_str,round(oddsratio,4),round(lci,4), round(uci,4))\n",
    "\n",
    "# for each polymorphism just do the same distr. comparisons in between populations \n",
    "def compare_between_populations_for_a_polymorphism(data,labels,poly,book):\n",
    "    # All desired comparisons for producing stats\n",
    "    comparison_list = [['GREEKS','AFRICANS'],\n",
    "                    ['SEC','AMERICANS'],\n",
    "                    ['SEC','EAST ASIANS'],\n",
    "                    ['SEC','SOUTH ASIANS'],\n",
    "                    ['SEC','EUROPEANS'],\n",
    "                    ['SEC','GROUP1=CEU+FIN+GBR'],\n",
    "                    ['GROUP1=CEU+FIN+GBR','GROUP2=IBS+TSI+SEC'],\n",
    "                    ['SEC','GROUP3=IBS+TSI'],\n",
    "                    ['SEC','ALL']]\n",
    "    \n",
    "    ws = book.add_sheet(str(poly))\n",
    "    fout = open(result_filepath+'_'+str(poly)+'.txt','w')\n",
    "    header_str = 'Group_1,Group_2,p_value_fischer,odds_ratio,Confidence_Interval_95'\n",
    "    fout.write('Group_1,Group_2,p_value_fischer,odds_ratio,Confidence_Interval_95%\\n')\n",
    "    \n",
    "    for j in range(len(header_str.split(','))):\n",
    "        ws.write(0,j,header_str.split(',')[j])\n",
    "    \n",
    "    i = 1\n",
    "    for comp_tuple in comparison_list:\n",
    "        try: \n",
    "#             print data\n",
    "            matrix = data[comp_tuple].as_matrix()\n",
    "        except:\n",
    "            print \"Polymorphism: {} does not contain comparison tuple {}\".format(poly,comp_tuple)\n",
    "            \n",
    "        stats = get_stats_from_matrix(matrix)\n",
    "        result_str = str(comp_tuple[0])+','+comp_tuple[1]+','+stats \n",
    "        fout.write(result_str+ \"\\n\")\n",
    "        print result_str\n",
    "        print matrix\n",
    "        \n",
    "        for j in range(len(result_str.split(','))):\n",
    "            ws.write(i,j,result_str.split(',')[j])\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    fout.close()\n",
    "    return book\n",
    "        \n",
    "book = xlwt.Workbook()\n",
    "for poly,v in alleles_agg_data.items():\n",
    "    book = compare_between_populations_for_a_polymorphism(v['data'],v['labels'],poly,book)\n",
    "book.save(result_filepath+'.xls')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "obs = np.array([[1930, 405], [112, 23]])\n",
    "print stats.fisher_exact(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
